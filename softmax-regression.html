<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Softmax Regression (SR) - Liebing&#39;s Homepage</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="">



<meta name="keywords" content="code">



    <meta name="description" content="Softmax regression (SR) (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. Same as the blog about LR, this blog will">
<meta property="og:type" content="article">
<meta property="og:title" content="Softmax Regression (SR)">
<meta property="og:url" content="http://yoursite.com/2019/07/02/Softmax-Regression/index.html">
<meta property="og:site_name" content="Liebing&#39;s Homepage">
<meta property="og:description" content="Softmax regression (SR) (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. Same as the blog about LR, this blog will">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-07-02T04:00:00.000Z">
<meta property="article:modified_time" content="2021-12-21T11:44:43.447Z">
<meta property="article:author" content="Liebing">
<meta property="article:tag" content="Algorithm">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/img/favicon.ico">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    

<meta name="generator" content="Hexo 4.2.0"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/categories">Cats</a>
            
            <a class="navbar-item "
               href="/tags">Tags</a>
            
            <a class="navbar-item "
               href="/courses">Courses</a>
            
            <a class="navbar-item "
               href="/bio">Bio</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            <div class="navbar-item is-hoverable has-dropdown is-hidden-mobile is-hidden-tablet-only toc">
                <a class="navbar-item" title="Table of Contents">
                    <i class="fa fa-list"></i>
                </a>
                <div class="navbar-dropdown is-right">
                    
                    
                    
                    
                    <a class="navbar-item" href="#Softmax-function">1&nbsp;&nbsp;<b>Softmax function</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#Modeling-approach">2&nbsp;&nbsp;<b>Modeling approach</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#Loss-function">3&nbsp;&nbsp;<b>Loss function</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#Gradient">4&nbsp;&nbsp;<b>Gradient</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#Implementation">5&nbsp;&nbsp;<b>Implementation</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#Example">6&nbsp;&nbsp;<b>Example</b></a>
                    
                </div>
            </div>
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/LB-Yu" target="_blank" rel="noopener">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            <a class="navbar-item" title="知" href="https://www.zhihu.com/people/liebingyu" target="_blank" rel="noopener">
                
                知
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            Softmax Regression (SR)
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-07-02T04:00:00.000Z" itemprop="datePublished">Jul 2 2019</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            8 minutes read (About 1179 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>Softmax regression (SR) (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. Same as the <a href="/2019/08/02/Logistic-Regression">blog</a> about LR, this blog will detail the <strong>modeling approach</strong>, <strong>loss function</strong>, <strong>forward and backward propagation</strong> of SR. In the end, I will use python with numpy to implement SR and give the use on data sets iris and mnist. You can find all the code <a href="https://github.com/LB-Yu/publication/tree/master/sr" target="_blank" rel="noopener">here</a>.</p>
<a id="more"></a>
<h1 id="Softmax-function"><a href="#Softmax-function" class="headerlink" title="Softmax function"></a>Softmax function</h1><p>The softmax function is defined by the following formula. Where <script type="math/tex">K</script> is the number of classes and <script type="math/tex">K \geqslant 2</script>.</p>
<script type="math/tex; mode=display">softmax(x)=\frac{1}{\sum_{j=1}^{K}e^{x^{(j)}}}\begin{bmatrix} e^{x^{(1)}}\\ e^{x^{(2)}}\\ \vdots \\ e^{x^{(K)}} \end{bmatrix}</script><p>Unfortunately, the original softmax definition has a numerical overflow problem in actual use. For a large positive <script type="math/tex">x^{(i)}</script> value, the value of <script type="math/tex">e^{x^{(i)}}</script> may be quite large and cause a numerical overflow. Similarly, for a smaller negative <script type="math/tex">x^{(i)}</script> value, the value of <script type="math/tex">e^{x^{(i)}}</script> may be very close to zero, resulting in a numerical underflow. Therefore, in practice we use the following equivalent formula.</p>
<script type="math/tex; mode=display">softmax(x-D)=\frac{1}{\sum_{j=1}^{K}e^{x^{(j)-D}}}\begin{bmatrix} e^{x^{(1)}-D}\\ e^{x^{(2)}-D}\\ \vdots \\ e^{x^{(K)}-D} \end{bmatrix}=\frac{1}{e^{-D}\sum_{j=1}^{K}e^{x^{(j)}}}\begin{bmatrix} e^{-D}e^{x^{(1)}}\\ e^{-D}e^{x^{(2)}}\\ \vdots \\ e^{-D}e^{x^{(K)}} \end{bmatrix}=softmax(x)</script><p>Where <script type="math/tex">D=max(x)</script>.<br>We need to use the derivative of softmax in backpropagation, so let&#x2019;s calculate it first. For writing convenience, let <script type="math/tex">\hat{y}=softmax(x)</script>, then <script type="math/tex">\hat{y^{(i)}}=\frac{e^{x^{(i)}}}{\sum_{j=1}^{K}e^{x^{(j)}}}</script>.</p>
<script type="math/tex; mode=display">if \ j=i, \ \ \ \ \frac{\partial \hat{y^{(i)}}}{\partial x^{(j)}}=\frac{e^{x^{(i)}}\sum_{j=1}^{K}e^{x^{(j)}}-e^{x^{(i)}}e^{x^{(j)}}}{(\sum_{j=1}^{K}e^{x^{(j)}})^2}=\hat{y^{(i)}}-(\hat{y^{(i)}})^2</script><script type="math/tex; mode=display">if \ j \neq i, \ \ \ \ \frac{\partial \hat{y^{(i)}}}{\partial x^{(j)}}=\frac{-e^{x^{(i)}e^{x^{(j)}}}}{(\sum_{j=1}{k}e^{x^{(j)}})^2}=-\hat{y^{(i)}}\hat{y^{(j)}}</script><h1 id="Modeling-approach"><a href="#Modeling-approach" class="headerlink" title="Modeling approach"></a>Modeling approach</h1><p>In LR we assumed that the labels were binary: <script type="math/tex">y\in {\{0, 1\}}</script>. SR allows us to handle <script type="math/tex">K</script> classification problem. In SR we often use one hot vector to represent the label. For example, in the MNIST digit recognition task, we will use <script type="math/tex">y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]^T</script> to represent the label of the image with the number 3. In SR we use softmax function to model probability. Suppose we have a training set <script type="math/tex">{\{(x_1, y_1), (x_2, y_2), ..., (x_m, y_m)\}}</script> of <script type="math/tex">m</script> labeled examples, where the input features are <script type="math/tex">x_i \in \Re^{[n, 1]}</script>. We can use the <script type="math/tex">i</script>-th output of the softmax function as the probability that the current sample belongs to the <script type="math/tex">i</script>-th class. The formal expression is as follows.</p>
<script type="math/tex; mode=display">P(y^{(i)}=1|x;w^{(i)}, b^{(i)})=\frac{e^{(w^{(i)})^Tx+b^{(i)}}}{\sum_{j=1}^{K}e^{(w^{(j)})^Tx+b^{(j)}}}</script><p>Where <script type="math/tex">w^{(i)} \in \Re^{[n, 1]}</script>, <script type="math/tex">w=\begin{bmatrix} |& |& |& |\\ w^{(1)}& w^{(2)}& \cdots & w^{(K)} \\ |&  |&  |& | \end{bmatrix} \in \Re^{[n, K]}</script>, <script type="math/tex">b^{(i)} \in \Re</script>, <script type="math/tex">b=\begin{bmatrix} b^{(1)} & b^{(2)} & \cdots & b^{(K)} \end{bmatrix} \in \Re^{[1, K]}</script>.<br>For the convenience of writing, let <script type="math/tex">\hat{y^{(i)}}=P(y^{(i)}=1|x;w^{(i)}, b^{(i)})</script>.</p>
<h1 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h1><p>In SR our goal is to </p>
<script type="math/tex; mode=display">maximize \ \ \ \ \prod_{i=1}^{K}(P(y^{(i)}=1|x;w^{(i)},b^{(i)}))^{I\{y^{(i)}=1\}}</script><script type="math/tex; mode=display">maximize \ \ \ \ \sum_{i=1}^{K}I\{y^{(i)}=1\}log(\hat{y^{(i)}})</script><script type="math/tex; mode=display">minimize \ \ \ \ -\sum_{i=1}^{K}I\{y^{(i)}=1\}log(\hat{y^{(i)}})=-\sum_{i=1}^{K}y^{(i)}log(\hat{y^{(i)}})</script><p>So the loss function of SR is:</p>
<script type="math/tex; mode=display">\mathcal L(y,\hat{y})=-\sum_{i=1}^{K}y^{(i)}log(\hat{y^{(i)}})</script><p>Note: <script type="math/tex">I</script> is the indicator function, in which</p>
<script type="math/tex; mode=display">\left\{\begin{matrix}
 I\{condition\}=1& if \ condition=true \\ 
 I\{condition\}=0& else 
\end{matrix}\right.</script><h1 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h1><p>The forward propagation of SR is similar with LR, for one example:</p>
<script type="math/tex; mode=display">z=w^Tx+b^T</script><script type="math/tex; mode=display">\hat{y}=softmax(z)</script><p>vectorization:</p>
<script type="math/tex; mode=display">Z=Xw+b</script><script type="math/tex; mode=display">\hat{Y}=softmax(Z)</script><p>We can derivative the gradient based on the chain rule. For one example:</p>
<script type="math/tex; mode=display">\frac{\partial \mathcal L}{\partial z^{(i)}}=\left\{\begin{matrix}
-\frac{1}{\hat{y^{(k)}}}(\hat{y^{(k)}}-(\hat{y^{(k)}})^2)=\hat{y^{(k)}}-1 & if \ i=k \\ 
-\frac{1}{\hat{y^{k}}}(-\hat{y^{(k)}}\hat{y^{(i)}})=\hat{y^{(i)}} & if \ i\neq k 
\end{matrix}\right. \Rightarrow \frac{\partial \mathcal L}{\partial z}=\hat{y}-y</script><script type="math/tex; mode=display">\frac{\partial z^{(i)}}{\partial w^{(i)}}=x,\ \ \ \   \frac{\partial z^{(i)}}{\partial b^{(i)}}=1</script><script type="math/tex; mode=display">\frac{\partial \mathcal L}{\partial w^{(i)}}=\frac{\partial \mathcal L}{z^{(i)}}\frac{\partial z^{(i)}}{\partial w^{(i)}}=x(\hat{y^{(i)}}-y^{(i)}) \Rightarrow \frac{\partial \mathcal L}{\partial w}=x(\hat{y}-y)^T</script><script type="math/tex; mode=display">\frac{\partial \mathcal L}{b^{(i)}}=\frac{\partial \mathcal L}{\partial z^{(i)}}\frac{\partial z^{(i)}}{\partial b^{(i)}}=\hat{y^{(i)}}-y^{(i)} \Rightarrow \frac{\partial \mathcal L}{\partial b}=(\hat{y}-y)^T</script><p>vectorization:</p>
<script type="math/tex; mode=display">\frac{\partial \mathcal L}{\partial w}=\frac{1}{m}X^T(\hat{Y}-Y)</script><script type="math/tex; mode=display">\frac{\partial \mathcal L}{\partial b}= \frac{1}{m}\sum_{row}(\hat{Y}-Y)</script><h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><p>Here we use python with numpy to implement the forward and backward propagation of SR.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax</span><span class="hljs-params">(x)</span>:</span></span><br><span class="line">    <span class="hljs-string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="hljs-string">    Softmax regression for a vector or matrix.</span></span><br><span class="line"><span class="hljs-string">    Args:</span></span><br><span class="line"><span class="hljs-string">        x: [n_examples, n_classes]</span></span><br><span class="line"><span class="hljs-string">    Returns: values after softmax.</span></span><br><span class="line"><span class="hljs-string">    &quot;&quot;&quot;</span></span><br><span class="line">    b = x - np.max(x, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)</span><br><span class="line">    expb = np.exp(b)</span><br><span class="line">    softmax = expb / np.sum(expb, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)</span><br><span class="line">    <span class="hljs-keyword">return</span> softmax</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SoftmaxRegression</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, max_iter=<span class="hljs-number">200</span>, learning_rate=<span class="hljs-number">0.01</span>)</span>:</span></span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span><span class="hljs-params">(self, X, Y)</span>:</span></span><br><span class="line">        <span class="hljs-string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="hljs-string">        Train the model.</span></span><br><span class="line"><span class="hljs-string">        Args:</span></span><br><span class="line"><span class="hljs-string">            X: [n_samples, n_features]</span></span><br><span class="line"><span class="hljs-string">            Y: [n_samples, n_classes]</span></span><br><span class="line"><span class="hljs-string">        &quot;&quot;&quot;</span></span><br><span class="line">        m, n = X.shape</span><br><span class="line">        _, K = Y.shape</span><br><span class="line">        self.w_ = np.zeros([n, K])</span><br><span class="line">        self.b_ = np.zeros([<span class="hljs-number">1</span>, K])</span><br><span class="line">        self.cost_ = []</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(self.max_iter):</span><br><span class="line">            Y_hat = self.predict(X)</span><br><span class="line"></span><br><span class="line">            cost = -np.sum(Y * np.log(Y_hat)) / m</span><br><span class="line"></span><br><span class="line">            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:</span><br><span class="line">                print(<span class="hljs-string">&quot;Step: &quot;</span> + str(i) + <span class="hljs-string">&quot;, Cost: &quot;</span> + str(cost))</span><br><span class="line"></span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line"></span><br><span class="line">            self.w_ -= self.learning_rate * np.dot(X.T, Y_hat - Y) / m</span><br><span class="line">            self.b_ -= self.learning_rate * np.sum(Y_hat - Y, axis=<span class="hljs-number">0</span>) / m</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(self, X)</span>:</span></span><br><span class="line">        <span class="hljs-string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="hljs-string">        Predict the given examples.</span></span><br><span class="line"><span class="hljs-string">        Args:</span></span><br><span class="line"><span class="hljs-string">            X: [n_samples, n_features]</span></span><br><span class="line"><span class="hljs-string">        &quot;&quot;&quot;</span></span><br><span class="line">        z = np.dot(X, self.w_)</span><br><span class="line">        <span class="hljs-keyword">return</span> softmax(np.dot(X, self.w_) + self.b_)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span><span class="hljs-params">(self, X, Y)</span>:</span></span><br><span class="line">        Y_hat = self.predict(X)</span><br><span class="line">        Y_hat = np.argmax(Y_hat, axis=<span class="hljs-number">1</span>)</span><br><span class="line">        Y = np.argmax(Y, axis=<span class="hljs-number">1</span>)</span><br><span class="line">        true_num = np.sum(Y_hat == Y)</span><br><span class="line">        <span class="hljs-keyword">return</span> true_num / len(X)</span><br></pre></td></tr></tbody></table></figure>

<h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h1><p>In order to verify the correctness of the implementation. I experimented on the irsi dataset and the mnist dataset. The parameters and results of the experiment are as follows:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>iris</th>
<th>mnist</th>
</tr>
</thead>
<tbody>
<tr>
<td>learnig rate</td>
<td>0.1</td>
<td>0.01</td>
</tr>
<tr>
<td>max iterate</td>
<td>100</td>
<td>10000</td>
</tr>
<tr>
<td>test accuracy</td>
<td>100%</td>
<td>90.98%</td>
</tr>
</tbody>
</table>
</div>
<p>You can find the all the experimental code <a href="https://github.com/LB-Yu/publication/tree/master/sr" target="_blank" rel="noopener">here</a> and reproduce the experimental results.</p>
</body></html>
    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/Algorithm/">#Algorithm</a></span>
    
    </div>
    
    
    <div class="columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2019/07/22/Automatic-Differentiation-Based-on-Computation-Graph/">Automatic Differentiation Based on Computation Graph</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2019/07/01/Logistic-Regression/">Logistic Regression (LR)</a>
            
        </span>
    </div>
    
</article>


<div class="sharebox">
    
<div class="sharethis-inline-share-buttons"></div>
<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5e63913dd0c39800126ea9e7&amp;product=inline-share-buttons&amp;cms=sop' async='async'></script>

</div>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<div id="valine-thread"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//cdn.jsdelivr.net/gh/AshinWang/SimpleValine@v0.1/SimpleValine.min.js'></script>
<script>
    new Valine({
        el: '#valine-thread',
        appId: 'v4Ich4NMxLXYhCkPcb1OmVPR-gzGzoHsz',
        appKey: 'b5fiVY3XvcAwzJ06YR8rFCAj',
        notify: true,
        verify: false,
        avatar: '',
        placeholder: 'If you have any questions, please comment here!',
        meta: ['nick', 'mail'],
        visitor: true,
        lang: 'en'
    })
</script>


</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2018-2021 Liebing&nbsp;. 
                <span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span> UV, </span>
                <span id="busuanzi_container_site_pv"> <span id="busuanzi_value_site_pv"></span> PV</span>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="一行代码, 点滴生活!" href="">
                    
                    一行代码, 点滴生活!
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>

    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>